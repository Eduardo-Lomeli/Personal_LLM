{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load the fine-tuning data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "file_path = \"../output/fine_tuning/data/fine_tuning.json\"\n",
    "with open(file_path, \"r\") as file:\n",
    "    data = json.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Load the tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from minbpe import RegexTokenizer\n",
    "\n",
    "tokenizer = RegexTokenizer()\n",
    "tokenizer.load(model_file=\"../output/tokenizer/dataset_tokenizer.model\")\n",
    "\n",
    "\n",
    "def get_vocab_size(tokenizer: RegexTokenizer) -> int:\n",
    "    vocab = tokenizer.vocab\n",
    "    special_tokens = tokenizer.special_tokens\n",
    "\n",
    "    return len(vocab) + len(special_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Tokenize the sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_data = []\n",
    "for item in data:\n",
    "    tokenized_item = tokenizer.encode(item, allowed_special=\"all\")\n",
    "    tokenized_data.append(tokenized_item)\n",
    "\n",
    "len(tokenized_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Split the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to be careful when splitting the data. We want to keep the multi-turn conversations complete in each part. So, the training and validation sets should start with a `You` message and end with an `Assistant` message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: \n",
      "Start message: <|startoftext|>Eduardo Lomeli\n",
      "End message: <|startoftext|>User 2:\n",
      "[08/11/25, 20:56:47] Eduardo Lomeli\n",
      "\n",
      "Validation set: \n",
      "Start message: <|startoftext|>User 2\n",
      "End message: <|startoftext|>User 2\n"
     ]
    }
   ],
   "source": [
    "initial_split_index = int(0.95 * len(data))\n",
    "\n",
    "# Adjusting the index to ensure that the training set ends with \"Assistant\" message\n",
    "# and that the validation set starts with \"You\" message\n",
    "\n",
    "# Scanning backward to find an Assistant message\n",
    "split_index = initial_split_index\n",
    "while split_index > 0 and not data[split_index-1].startswith('<|startoftext|>User 2:'):\n",
    "    split_index -= 1\n",
    "\n",
    "train_data = data[:split_index]\n",
    "val_data = data[split_index:]\n",
    "\n",
    "print(\"Training set: \")\n",
    "print(f\"Start message: {train_data[0].split('<|separator|>')[0]}\")\n",
    "print(f\"End message: {train_data[-1].split('<|separator|>')[0]}\")\n",
    "\n",
    "print(\"\\nValidation set: \")\n",
    "print(f\"Start message: {val_data[0].split('<|separator|>')[0]}\")\n",
    "print(f\"End message: {val_data[-1].split('<|separator|>')[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We got the index that we should use to split the data. Now, let's split the tokenized data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = tokenized_data[:split_index]\n",
    "val_data = tokenized_data[split_index:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we need to combine the `You` and `Assistant` turns into one sequence. We will make sure that the resulting sequence does not exceed the `block_size`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "block_size = 1024\n",
    "\n",
    "\n",
    "def combine_turns(data: list[list[int]], should_trim_long_sequences: bool) -> list[list[int]]:\n",
    "    combined_turns_data = []\n",
    "    for i in range(0, len(data)-1, 2):\n",
    "        you_message = data[i]\n",
    "        assistant_message = data[i+1]\n",
    "        if not you_message or not assistant_message:\n",
    "            continue\n",
    "\n",
    "        final_message = you_message + assistant_message\n",
    "        if len(final_message) > block_size and should_trim_long_sequences:\n",
    "            final_message = final_message[-block_size:]\n",
    "\n",
    "        combined_turns_data.append(final_message)\n",
    "    return combined_turns_data\n",
    "\n",
    "\n",
    "combined_train_data = combine_turns(\n",
    "    data=train_data,\n",
    "    should_trim_long_sequences=True\n",
    ")\n",
    "combined_val_data = combine_turns(\n",
    "    data=val_data,\n",
    "    should_trim_long_sequences=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data\n",
      "Length before: 17950\n",
      "Length after: 8975\n",
      "\n",
      "Validation data\n",
      "Length before: 9978\n",
      "Length after: 4989\n"
     ]
    }
   ],
   "source": [
    "print(\"Train data\")\n",
    "print(f\"Length before: {len(train_data)}\")\n",
    "print(f\"Length after: {len(combined_train_data)}\")\n",
    "\n",
    "print(\"\\nValidation data\")\n",
    "print(f\"Length before: {len(val_data)}\")\n",
    "print(f\"Length after: {len(combined_val_data)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will merge the `You` and `Assistant` parts into one sequence. Then, we will try to combine multiple sequences of `You` and `Assistant` into a single input, but only if the sequence length stays smaller than the block size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_conversation_turns(combined_data: list[list[int]], block_size: int) -> list[list[int]]:\n",
    "    new_data = []\n",
    "    current_sequence = []\n",
    "\n",
    "    for sequence in combined_data:\n",
    "        if len(current_sequence) + len(sequence) <= block_size:\n",
    "            current_sequence.extend(sequence)\n",
    "        else:\n",
    "            if current_sequence:\n",
    "                new_data.append(current_sequence)\n",
    "            current_sequence = sequence.copy()\n",
    "\n",
    "    # Add the last block if it's not empty\n",
    "    if current_sequence:\n",
    "        new_data.append(current_sequence)\n",
    "\n",
    "    return new_data\n",
    "\n",
    "\n",
    "merged_train_data = merge_conversation_turns(\n",
    "    combined_data=combined_train_data,\n",
    "    block_size=block_size\n",
    ")\n",
    "merged_val_data = merge_conversation_turns(\n",
    "    combined_data=combined_val_data,\n",
    "    block_size=block_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8975, 389)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(combined_train_data), len(merged_train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's convert each sequence of tokens into a tensor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since our token sequences don't all have the same length, we can't turn the data into a tensor all at once. To do that, all sequences need to have the same length.\n",
    "\n",
    "That's why we need to use padding to fix this problem. We can add padding at the start or end of the sequence. Let's add it to the start."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([389, 1024]), torch.Size([207, 1024]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.manual_seed(3647)\n",
    "\n",
    "# The token `<|padding|>` is used to mask the padding tokens.\n",
    "# Masking means the model will ignore these tokens during training.\n",
    "# In other words, the loss will not be calculated for these tokens.\n",
    "padding_token = tokenizer.special_tokens[\"<|padding|>\"]\n",
    "\n",
    "\n",
    "def apply_padding_to_data(data: list[list[int]], block_size: int, padding_token: int) -> torch.Tensor:\n",
    "    tensors = []\n",
    "    for i in range(len(data)):\n",
    "        tensor = torch.tensor(data[i])\n",
    "        padded_tensor = torch.nn.functional.pad(\n",
    "            input=tensor,\n",
    "            # for right padding:\n",
    "            pad=(0, block_size - len(tensor)),\n",
    "            # pad=(block_size - len(tensor), 0),\n",
    "            value=padding_token\n",
    "        )\n",
    "        tensors.append(padded_tensor)\n",
    "\n",
    "    return torch.stack(tensors)\n",
    "\n",
    "\n",
    "train_data_tensor = apply_padding_to_data(\n",
    "    data=merged_train_data,\n",
    "    block_size=block_size,\n",
    "    padding_token=padding_token\n",
    ")\n",
    "val_data_tensor = apply_padding_to_data(\n",
    "    data=merged_val_data,\n",
    "    block_size=block_size,\n",
    "    padding_token=padding_token\n",
    ")\n",
    "\n",
    "train_data_tensor.shape, val_data_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([16384,    69,   641,  ..., 16388, 16388, 16388])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_tensor[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([16384,    85,  1039,  ..., 16388, 16388, 16388])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_data_tensor[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Creat the data loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "class FineTuningDataset(Dataset):\n",
    "    def __init__(self, data: torch.Tensor, device: torch.device, padding_token: int):\n",
    "        self.data = data  # shape: (num_samples, block_size)\n",
    "        self.device = device\n",
    "        self.padding_token = padding_token\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index: int) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        sample = self.data[index]\n",
    "        x = sample.to(self.device)\n",
    "        y = sample[1:].to(self.device)\n",
    "        padding_tensor = torch.tensor([self.padding_token], device=self.device)\n",
    "        y = torch.cat((y, padding_tensor))\n",
    "        return x, y\n",
    "\n",
    "\n",
    "batch_size = 2\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "train_dataset = FineTuningDataset(\n",
    "    data=train_data_tensor,\n",
    "    device=device,\n",
    "    padding_token=padding_token\n",
    ")\n",
    "train_loader = DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_dataset = FineTuningDataset(\n",
    "    data=val_data_tensor,\n",
    "    device=device,\n",
    "    padding_token=padding_token\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    dataset=val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 1024]), torch.Size([2, 1024]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = next(iter(train_loader))\n",
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load the saved checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1ff666265b0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.manual_seed(3647)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36.23425 M parameters\n"
     ]
    }
   ],
   "source": [
    "from transformer.model import GPTLanguageModel\n",
    "\n",
    "block_size = 1024\n",
    "n_embd = 512\n",
    "n_head = 32\n",
    "n_layer = 6\n",
    "dropout = 0.2\n",
    "batch_size = 2\n",
    "vocab_size = get_vocab_size(tokenizer)\n",
    "\n",
    "model = GPTLanguageModel(\n",
    "    vocab_size=vocab_size,\n",
    "    block_size=block_size,\n",
    "    n_embd=n_embd,\n",
    "    n_head=n_head,\n",
    "    n_layer=n_layer,\n",
    "    dropout=dropout,\n",
    "    device=device,\n",
    "    ignore_index=tokenizer.special_tokens[\"<|padding|>\"],\n",
    ").to(device)\n",
    "#model = torch.compile(model)\n",
    "\n",
    "print(sum(p.numel() for p in model.parameters())/1e6, 'M parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint_path = \"../output/pre_training/run_4/checkpoint_15000.pth\"\n",
    "checkpoint = torch.load(checkpoint_path, weights_only=True)\n",
    "model_state_dict = checkpoint[\"model_state_dict\"]\n",
    "model.load_state_dict(model_state_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate from the model to make sure that the weights were loaded correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hola como estas?  es inevitabletentó y ausentarse de el pobre Willoughby, ¿Nada, ¿Es que observamos en sí mismos, Elinor! Prefieres buscar el infortunio para el mundo para el infortunio para Marianne y la culpa para el pobre Willoughby, Elinor! Mi otros planes que en sí mismos, antes que en general nos ha demostrado. Pero habría sido antes que en esa una disculpa para querer, porque se le debe al atolondramiento, y es posible hacer en sí mismos, simplemente\n"
     ]
    }
   ],
   "source": [
    "input_tokens = tokenizer.encode(\"Hola como estas? \", allowed_special=\"all\")\n",
    "input_tokens = torch.tensor(\n",
    "    input_tokens, dtype=torch.long).unsqueeze(0).to(device)\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    output = model.generate(input_tokens=input_tokens, max_new_tokens=100)\n",
    "\n",
    "print(tokenizer.decode(output[0].tolist()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Estimate loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def estimate_loss(\n",
    "    model: torch.nn.Module,\n",
    "    train_loader: DataLoader,\n",
    "    val_loader: DataLoader,\n",
    ") -> Dict[str, float]:\n",
    "    output = {}\n",
    "    model.eval()\n",
    "\n",
    "    for split, loader in [('train', train_loader), ('val', val_loader)]:\n",
    "        losses = []\n",
    "        for x, y in loader:\n",
    "            with torch.no_grad():\n",
    "                _, loss = model(x, y)\n",
    "            losses.append(loss.item())\n",
    "        output[split] = sum(losses) / len(losses)\n",
    "\n",
    "    model.train()\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Save checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(\n",
    "    model: GPTLanguageModel,\n",
    "    optimizer: torch.optim.Optimizer,\n",
    "    epoch: int,\n",
    "    loss: float,\n",
    "    file_path: str = \"checkpoint.pth\"\n",
    ") -> None:\n",
    "    checkpoint = {\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'loss': loss\n",
    "    }\n",
    "    torch.save(checkpoint, file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0 / step 0: train loss 12.9760, val loss 12.8371\n",
      "iteration 0 / step 5: train loss 9.0214, val loss 9.0044\n",
      "iteration 0 / step 10: train loss 7.8538, val loss 7.8397\n",
      "iteration 0 / step 15: train loss 7.0763, val loss 7.0951\n",
      "iteration 0 / step 20: train loss 6.4518, val loss 6.4474\n",
      "iteration 0 / step 25: train loss 5.9763, val loss 6.0069\n",
      "iteration 0 / step 30: train loss 5.5643, val loss 5.6096\n",
      "iteration 0 / step 35: train loss 5.2686, val loss 5.3173\n",
      "iteration 0 / step 40: train loss 4.9768, val loss 5.0558\n",
      "iteration 0 / step 45: train loss 4.7249, val loss 4.7946\n",
      "iteration 0 / step 50: train loss 4.5027, val loss 4.5906\n",
      "iteration 0 / step 55: train loss 4.3308, val loss 4.4194\n",
      "iteration 0 / step 60: train loss 4.2151, val loss 4.3252\n",
      "iteration 0 / step 65: train loss 4.1101, val loss 4.2255\n",
      "iteration 0 / step 70: train loss 4.0514, val loss 4.1723\n",
      "iteration 0 / step 75: train loss 3.9877, val loss 4.1103\n",
      "iteration 0 / step 80: train loss 3.9417, val loss 4.0970\n",
      "iteration 0 / step 85: train loss 3.8868, val loss 4.0514\n",
      "iteration 0 / step 90: train loss 3.8443, val loss 4.0311\n",
      "iteration 0 / step 95: train loss 3.8115, val loss 4.0086\n",
      "iteration 0 / step 100: train loss 3.7796, val loss 3.9951\n",
      "iteration 0 / step 105: train loss 3.7497, val loss 3.9574\n",
      "iteration 0 / step 110: train loss 3.7233, val loss 3.9634\n",
      "iteration 0 / step 115: train loss 3.6869, val loss 3.9301\n",
      "iteration 0 / step 120: train loss 3.6604, val loss 3.9040\n",
      "iteration 0 / step 125: train loss 3.6493, val loss 3.9028\n",
      "iteration 0 / step 130: train loss 3.6180, val loss 3.8775\n",
      "iteration 0 / step 135: train loss 3.5998, val loss 3.8684\n",
      "iteration 0 / step 140: train loss 3.5784, val loss 3.8446\n",
      "iteration 0 / step 145: train loss 3.5586, val loss 3.8342\n",
      "iteration 0 / step 150: train loss 3.5426, val loss 3.8222\n",
      "iteration 0 / step 155: train loss 3.5404, val loss 3.8302\n",
      "iteration 0 / step 160: train loss 3.5077, val loss 3.7978\n",
      "iteration 0 / step 165: train loss 3.4956, val loss 3.7882\n",
      "iteration 0 / step 170: train loss 3.4812, val loss 3.7899\n",
      "iteration 0 / step 175: train loss 3.4636, val loss 3.7713\n",
      "iteration 0 / step 180: train loss 3.4505, val loss 3.7642\n",
      "iteration 0 / step 185: train loss 3.4386, val loss 3.7527\n",
      "iteration 0 / step 190: train loss 3.4229, val loss 3.7575\n",
      "iteration 0 / step 194: train loss 3.4130, val loss 3.7387\n",
      "iteration 1 / step 0: train loss 3.4118, val loss 3.7346\n",
      "iteration 1 / step 5: train loss 3.3942, val loss 3.7248\n",
      "iteration 1 / step 10: train loss 3.3877, val loss 3.7312\n",
      "iteration 1 / step 15: train loss 3.3818, val loss 3.7234\n",
      "iteration 1 / step 20: train loss 3.3635, val loss 3.7168\n",
      "iteration 1 / step 25: train loss 3.3561, val loss 3.7168\n",
      "iteration 1 / step 30: train loss 3.3425, val loss 3.7107\n",
      "iteration 1 / step 35: train loss 3.3326, val loss 3.6993\n",
      "iteration 1 / step 40: train loss 3.3183, val loss 3.6882\n",
      "iteration 1 / step 45: train loss 3.3110, val loss 3.6845\n",
      "iteration 1 / step 50: train loss 3.2991, val loss 3.6851\n",
      "iteration 1 / step 55: train loss 3.2884, val loss 3.6732\n",
      "iteration 1 / step 60: train loss 3.2841, val loss 3.6601\n",
      "iteration 1 / step 65: train loss 3.2843, val loss 3.6762\n",
      "iteration 1 / step 70: train loss 3.2586, val loss 3.6382\n",
      "iteration 1 / step 75: train loss 3.2506, val loss 3.6445\n",
      "iteration 1 / step 80: train loss 3.2432, val loss 3.6325\n",
      "iteration 1 / step 85: train loss 3.2268, val loss 3.6264\n",
      "iteration 1 / step 90: train loss 3.2229, val loss 3.6345\n",
      "iteration 1 / step 95: train loss 3.2199, val loss 3.6176\n",
      "iteration 1 / step 100: train loss 3.2018, val loss 3.6229\n",
      "iteration 1 / step 105: train loss 3.1958, val loss 3.6159\n",
      "iteration 1 / step 110: train loss 3.1880, val loss 3.6069\n",
      "iteration 1 / step 115: train loss 3.1788, val loss 3.6048\n",
      "iteration 1 / step 120: train loss 3.1700, val loss 3.5815\n",
      "iteration 1 / step 125: train loss 3.1777, val loss 3.6199\n",
      "iteration 1 / step 130: train loss 3.1674, val loss 3.6100\n",
      "iteration 1 / step 135: train loss 3.1556, val loss 3.5790\n",
      "iteration 1 / step 140: train loss 3.1517, val loss 3.5960\n",
      "iteration 1 / step 145: train loss 3.1344, val loss 3.5703\n",
      "iteration 1 / step 150: train loss 3.1319, val loss 3.5595\n",
      "iteration 1 / step 155: train loss 3.1210, val loss 3.5676\n",
      "iteration 1 / step 160: train loss 3.1150, val loss 3.5566\n",
      "iteration 1 / step 165: train loss 3.1119, val loss 3.5504\n",
      "iteration 1 / step 170: train loss 3.1037, val loss 3.5577\n",
      "iteration 1 / step 175: train loss 3.0932, val loss 3.5481\n",
      "iteration 1 / step 180: train loss 3.0909, val loss 3.5455\n",
      "iteration 1 / step 185: train loss 3.0770, val loss 3.5380\n",
      "iteration 1 / step 190: train loss 3.0756, val loss 3.5423\n",
      "iteration 1 / step 194: train loss 3.0754, val loss 3.5309\n",
      "iteration 2 / step 0: train loss 3.0735, val loss 3.5278\n",
      "iteration 2 / step 5: train loss 3.0645, val loss 3.5315\n",
      "iteration 2 / step 10: train loss 3.0661, val loss 3.5509\n",
      "iteration 2 / step 15: train loss 3.0586, val loss 3.5380\n",
      "iteration 2 / step 20: train loss 3.0459, val loss 3.5270\n",
      "iteration 2 / step 25: train loss 3.0473, val loss 3.5235\n",
      "iteration 2 / step 30: train loss 3.0430, val loss 3.5318\n",
      "iteration 2 / step 35: train loss 3.0320, val loss 3.5094\n",
      "iteration 2 / step 40: train loss 3.0368, val loss 3.5178\n",
      "iteration 2 / step 45: train loss 3.0226, val loss 3.5081\n",
      "iteration 2 / step 50: train loss 3.0199, val loss 3.5055\n",
      "iteration 2 / step 55: train loss 3.0202, val loss 3.5212\n",
      "iteration 2 / step 60: train loss 3.0181, val loss 3.5188\n",
      "iteration 2 / step 65: train loss 3.0066, val loss 3.5104\n",
      "iteration 2 / step 70: train loss 3.0046, val loss 3.5051\n",
      "iteration 2 / step 75: train loss 3.0106, val loss 3.5001\n",
      "iteration 2 / step 80: train loss 2.9984, val loss 3.5008\n",
      "iteration 2 / step 85: train loss 2.9865, val loss 3.4941\n",
      "iteration 2 / step 90: train loss 2.9892, val loss 3.5060\n",
      "iteration 2 / step 95: train loss 2.9793, val loss 3.4900\n",
      "iteration 2 / step 100: train loss 2.9709, val loss 3.4899\n",
      "iteration 2 / step 105: train loss 2.9722, val loss 3.4971\n",
      "iteration 2 / step 110: train loss 2.9651, val loss 3.4903\n",
      "iteration 2 / step 115: train loss 2.9566, val loss 3.4811\n",
      "iteration 2 / step 120: train loss 2.9552, val loss 3.4840\n",
      "iteration 2 / step 125: train loss 2.9473, val loss 3.4816\n",
      "iteration 2 / step 130: train loss 2.9403, val loss 3.4693\n",
      "iteration 2 / step 135: train loss 2.9481, val loss 3.4645\n",
      "iteration 2 / step 140: train loss 2.9499, val loss 3.4706\n",
      "iteration 2 / step 145: train loss 2.9304, val loss 3.4730\n",
      "iteration 2 / step 150: train loss 2.9297, val loss 3.4652\n",
      "iteration 2 / step 155: train loss 2.9244, val loss 3.4634\n",
      "iteration 2 / step 160: train loss 2.9215, val loss 3.4606\n",
      "iteration 2 / step 165: train loss 2.9149, val loss 3.4459\n",
      "iteration 2 / step 170: train loss 2.9126, val loss 3.4496\n",
      "iteration 2 / step 175: train loss 2.9077, val loss 3.4491\n",
      "iteration 2 / step 180: train loss 2.9034, val loss 3.4424\n",
      "iteration 2 / step 185: train loss 2.9058, val loss 3.4566\n",
      "iteration 2 / step 190: train loss 2.8990, val loss 3.4364\n",
      "iteration 2 / step 194: train loss 2.8996, val loss 3.4434\n",
      "iteration 3 / step 0: train loss 2.9021, val loss 3.4493\n",
      "iteration 3 / step 5: train loss 2.9030, val loss 3.4566\n",
      "iteration 3 / step 10: train loss 2.9076, val loss 3.4726\n",
      "iteration 3 / step 15: train loss 2.8891, val loss 3.4547\n",
      "iteration 3 / step 20: train loss 2.8799, val loss 3.4636\n",
      "iteration 3 / step 25: train loss 2.8781, val loss 3.4495\n",
      "iteration 3 / step 30: train loss 2.8738, val loss 3.4441\n",
      "iteration 3 / step 35: train loss 2.8689, val loss 3.4421\n",
      "iteration 3 / step 40: train loss 2.8740, val loss 3.4527\n",
      "iteration 3 / step 45: train loss 2.8647, val loss 3.4487\n",
      "iteration 3 / step 50: train loss 2.8633, val loss 3.4423\n",
      "iteration 3 / step 55: train loss 2.8603, val loss 3.4410\n",
      "iteration 3 / step 60: train loss 2.8535, val loss 3.4344\n",
      "iteration 3 / step 65: train loss 2.8535, val loss 3.4461\n",
      "iteration 3 / step 70: train loss 2.8441, val loss 3.4290\n",
      "iteration 3 / step 75: train loss 2.8415, val loss 3.4280\n",
      "iteration 3 / step 80: train loss 2.8380, val loss 3.4338\n",
      "iteration 3 / step 85: train loss 2.8348, val loss 3.4309\n",
      "iteration 3 / step 90: train loss 2.8296, val loss 3.4262\n",
      "iteration 3 / step 95: train loss 2.8270, val loss 3.4281\n",
      "iteration 3 / step 100: train loss 2.8267, val loss 3.4284\n",
      "iteration 3 / step 105: train loss 2.8238, val loss 3.4219\n",
      "iteration 3 / step 110: train loss 2.8288, val loss 3.4356\n",
      "iteration 3 / step 115: train loss 2.8579, val loss 3.4696\n",
      "iteration 3 / step 120: train loss 2.8403, val loss 3.4412\n",
      "iteration 3 / step 125: train loss 2.8175, val loss 3.4192\n",
      "iteration 3 / step 130: train loss 2.8161, val loss 3.4225\n",
      "iteration 3 / step 135: train loss 2.8136, val loss 3.4248\n",
      "iteration 3 / step 140: train loss 2.8116, val loss 3.4159\n",
      "iteration 3 / step 145: train loss 2.8067, val loss 3.3991\n",
      "iteration 3 / step 150: train loss 2.7966, val loss 3.4068\n",
      "iteration 3 / step 155: train loss 2.7993, val loss 3.4010\n",
      "iteration 3 / step 160: train loss 2.7874, val loss 3.4013\n",
      "iteration 3 / step 165: train loss 2.7946, val loss 3.4133\n",
      "iteration 3 / step 170: train loss 2.7842, val loss 3.4089\n",
      "iteration 3 / step 175: train loss 2.7856, val loss 3.3980\n",
      "iteration 3 / step 180: train loss 2.7741, val loss 3.4041\n",
      "iteration 3 / step 185: train loss 2.7796, val loss 3.3989\n",
      "iteration 3 / step 190: train loss 2.7730, val loss 3.3993\n",
      "iteration 3 / step 194: train loss 2.7673, val loss 3.3905\n",
      "iteration 4 / step 0: train loss 2.7683, val loss 3.3896\n",
      "iteration 4 / step 5: train loss 2.7790, val loss 3.4136\n",
      "iteration 4 / step 10: train loss 2.7708, val loss 3.4150\n",
      "iteration 4 / step 15: train loss 2.7649, val loss 3.4173\n",
      "iteration 4 / step 20: train loss 2.7574, val loss 3.4069\n",
      "iteration 4 / step 25: train loss 2.7573, val loss 3.4130\n",
      "iteration 4 / step 30: train loss 2.7574, val loss 3.4008\n",
      "iteration 4 / step 35: train loss 2.7618, val loss 3.4136\n",
      "iteration 4 / step 40: train loss 2.7547, val loss 3.4169\n",
      "iteration 4 / step 45: train loss 2.7449, val loss 3.4038\n",
      "iteration 4 / step 50: train loss 2.7501, val loss 3.4113\n",
      "iteration 4 / step 55: train loss 2.7390, val loss 3.4088\n",
      "iteration 4 / step 60: train loss 2.7407, val loss 3.4043\n",
      "iteration 4 / step 65: train loss 2.7360, val loss 3.3988\n",
      "iteration 4 / step 70: train loss 2.7416, val loss 3.4071\n",
      "iteration 4 / step 75: train loss 2.7483, val loss 3.4139\n",
      "iteration 4 / step 80: train loss 2.7361, val loss 3.4101\n",
      "iteration 4 / step 85: train loss 2.7253, val loss 3.3875\n",
      "iteration 4 / step 90: train loss 2.7258, val loss 3.3865\n",
      "iteration 4 / step 95: train loss 2.7169, val loss 3.3891\n",
      "iteration 4 / step 100: train loss 2.7244, val loss 3.4002\n",
      "iteration 4 / step 105: train loss 2.7222, val loss 3.3880\n",
      "iteration 4 / step 110: train loss 2.7125, val loss 3.3850\n",
      "iteration 4 / step 115: train loss 2.7101, val loss 3.3981\n",
      "iteration 4 / step 120: train loss 2.7161, val loss 3.4003\n",
      "iteration 4 / step 125: train loss 2.7068, val loss 3.3832\n",
      "iteration 4 / step 130: train loss 2.7057, val loss 3.3928\n",
      "iteration 4 / step 135: train loss 2.7112, val loss 3.3910\n",
      "iteration 4 / step 140: train loss 2.6993, val loss 3.3729\n",
      "iteration 4 / step 145: train loss 2.6958, val loss 3.3871\n",
      "iteration 4 / step 150: train loss 2.6999, val loss 3.3888\n",
      "iteration 4 / step 155: train loss 2.6978, val loss 3.3848\n",
      "iteration 4 / step 160: train loss 2.6982, val loss 3.3910\n",
      "iteration 4 / step 165: train loss 2.6847, val loss 3.3761\n",
      "iteration 4 / step 170: train loss 2.6935, val loss 3.3819\n",
      "iteration 4 / step 175: train loss 2.6802, val loss 3.3699\n",
      "iteration 4 / step 180: train loss 2.6747, val loss 3.3627\n",
      "iteration 4 / step 185: train loss 2.6726, val loss 3.3681\n",
      "iteration 4 / step 190: train loss 2.6768, val loss 3.3724\n",
      "iteration 4 / step 194: train loss 2.6787, val loss 3.3684\n",
      "iteration 5 / step 0: train loss 2.6728, val loss 3.3627\n",
      "iteration 5 / step 5: train loss 2.6796, val loss 3.3856\n",
      "iteration 5 / step 10: train loss 2.6748, val loss 3.3825\n",
      "iteration 5 / step 15: train loss 2.6712, val loss 3.3879\n",
      "iteration 5 / step 20: train loss 2.6758, val loss 3.3793\n",
      "iteration 5 / step 25: train loss 2.6632, val loss 3.3817\n",
      "iteration 5 / step 30: train loss 2.6564, val loss 3.3707\n",
      "iteration 5 / step 35: train loss 2.6550, val loss 3.3773\n",
      "iteration 5 / step 40: train loss 2.6540, val loss 3.3804\n",
      "iteration 5 / step 45: train loss 2.6497, val loss 3.3834\n",
      "iteration 5 / step 50: train loss 2.6493, val loss 3.3834\n",
      "iteration 5 / step 55: train loss 2.6505, val loss 3.3846\n",
      "iteration 5 / step 60: train loss 2.6508, val loss 3.3951\n",
      "iteration 5 / step 65: train loss 2.6489, val loss 3.3770\n",
      "iteration 5 / step 70: train loss 2.6396, val loss 3.3757\n",
      "iteration 5 / step 75: train loss 2.6337, val loss 3.3727\n",
      "iteration 5 / step 80: train loss 2.6309, val loss 3.3708\n",
      "iteration 5 / step 85: train loss 2.6369, val loss 3.3812\n",
      "iteration 5 / step 90: train loss 2.6301, val loss 3.3738\n",
      "iteration 5 / step 95: train loss 2.6339, val loss 3.3759\n",
      "iteration 5 / step 100: train loss 2.6259, val loss 3.3627\n",
      "iteration 5 / step 105: train loss 2.6271, val loss 3.3636\n",
      "iteration 5 / step 110: train loss 2.6265, val loss 3.3776\n",
      "iteration 5 / step 115: train loss 2.6159, val loss 3.3665\n",
      "iteration 5 / step 120: train loss 2.6155, val loss 3.3601\n",
      "iteration 5 / step 125: train loss 2.6147, val loss 3.3629\n",
      "iteration 5 / step 130: train loss 2.6107, val loss 3.3589\n",
      "iteration 5 / step 135: train loss 2.6092, val loss 3.3546\n",
      "iteration 5 / step 140: train loss 2.6117, val loss 3.3710\n",
      "iteration 5 / step 145: train loss 2.6094, val loss 3.3665\n",
      "iteration 5 / step 150: train loss 2.5984, val loss 3.3549\n",
      "iteration 5 / step 155: train loss 2.5971, val loss 3.3447\n",
      "iteration 5 / step 160: train loss 2.5982, val loss 3.3455\n",
      "iteration 5 / step 165: train loss 2.5967, val loss 3.3444\n",
      "iteration 5 / step 170: train loss 2.5874, val loss 3.3406\n",
      "iteration 5 / step 175: train loss 2.5891, val loss 3.3430\n",
      "iteration 5 / step 180: train loss 2.5881, val loss 3.3469\n",
      "iteration 5 / step 185: train loss 2.5845, val loss 3.3419\n",
      "iteration 5 / step 190: train loss 2.5834, val loss 3.3489\n",
      "iteration 5 / step 194: train loss 2.5854, val loss 3.3618\n",
      "iteration 6 / step 0: train loss 2.5963, val loss 3.3721\n",
      "iteration 6 / step 5: train loss 2.5841, val loss 3.3545\n",
      "iteration 6 / step 10: train loss 2.5852, val loss 3.3599\n",
      "iteration 6 / step 15: train loss 2.5838, val loss 3.3675\n",
      "iteration 6 / step 20: train loss 2.5761, val loss 3.3712\n",
      "iteration 6 / step 25: train loss 2.5695, val loss 3.3501\n",
      "iteration 6 / step 30: train loss 2.5685, val loss 3.3676\n",
      "iteration 6 / step 35: train loss 2.5681, val loss 3.3565\n",
      "iteration 6 / step 40: train loss 2.5719, val loss 3.3618\n",
      "iteration 6 / step 45: train loss 2.5661, val loss 3.3620\n",
      "iteration 6 / step 50: train loss 2.5637, val loss 3.3413\n",
      "iteration 6 / step 55: train loss 2.5619, val loss 3.3629\n",
      "iteration 6 / step 60: train loss 2.5627, val loss 3.3590\n",
      "iteration 6 / step 65: train loss 2.5654, val loss 3.3526\n",
      "iteration 6 / step 70: train loss 2.5617, val loss 3.3649\n",
      "iteration 6 / step 75: train loss 2.5577, val loss 3.3563\n",
      "iteration 6 / step 80: train loss 2.5549, val loss 3.3622\n",
      "iteration 6 / step 85: train loss 2.5604, val loss 3.3729\n",
      "iteration 6 / step 90: train loss 2.5526, val loss 3.3556\n",
      "iteration 6 / step 95: train loss 2.5498, val loss 3.3467\n",
      "iteration 6 / step 100: train loss 2.5523, val loss 3.3621\n",
      "iteration 6 / step 105: train loss 2.5504, val loss 3.3588\n",
      "iteration 6 / step 110: train loss 2.5424, val loss 3.3524\n",
      "iteration 6 / step 115: train loss 2.5380, val loss 3.3642\n",
      "iteration 6 / step 120: train loss 2.5398, val loss 3.3616\n",
      "iteration 6 / step 125: train loss 2.5434, val loss 3.3568\n",
      "iteration 6 / step 130: train loss 2.5396, val loss 3.3522\n",
      "iteration 6 / step 135: train loss 2.5350, val loss 3.3499\n",
      "iteration 6 / step 140: train loss 2.5301, val loss 3.3405\n",
      "iteration 6 / step 145: train loss 2.5264, val loss 3.3446\n",
      "iteration 6 / step 150: train loss 2.5317, val loss 3.3505\n",
      "iteration 6 / step 155: train loss 2.5239, val loss 3.3445\n",
      "iteration 6 / step 160: train loss 2.5201, val loss 3.3396\n",
      "iteration 6 / step 165: train loss 2.5248, val loss 3.3474\n",
      "iteration 6 / step 170: train loss 2.5216, val loss 3.3539\n",
      "iteration 6 / step 175: train loss 2.5154, val loss 3.3461\n",
      "iteration 6 / step 180: train loss 2.5181, val loss 3.3515\n",
      "iteration 6 / step 185: train loss 2.5190, val loss 3.3512\n",
      "iteration 6 / step 190: train loss 2.5093, val loss 3.3412\n",
      "iteration 6 / step 194: train loss 2.5116, val loss 3.3472\n",
      "iteration 7 / step 0: train loss 2.5114, val loss 3.3513\n",
      "iteration 7 / step 5: train loss 2.5125, val loss 3.3585\n",
      "iteration 7 / step 10: train loss 2.5088, val loss 3.3568\n",
      "iteration 7 / step 15: train loss 2.5095, val loss 3.3601\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 13\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_idx, (x_batch, y_batch) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_loader):\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;66;03m# Evaluation\u001b[39;00m\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m batch_idx \u001b[38;5;241m%\u001b[39m eval_interval \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m batch_idx \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(train_loader) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m---> 13\u001b[0m         losses \u001b[38;5;241m=\u001b[39m \u001b[43mestimate_loss\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[43m            \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m         train_losses\u001b[38;5;241m.\u001b[39mappend(losses[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     19\u001b[0m         val_losses\u001b[38;5;241m.\u001b[39mappend(losses[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\Eduar\\miniconda3\\envs\\vincent\\lib\\site-packages\\torch\\utils\\_contextlib.py:120\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    119\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 120\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "Cell \u001b[1;32mIn[22], line 18\u001b[0m, in \u001b[0;36mestimate_loss\u001b[1;34m(model, train_loader, val_loader)\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m     17\u001b[0m             _, loss \u001b[38;5;241m=\u001b[39m model(x, y)\n\u001b[1;32m---> 18\u001b[0m         losses\u001b[38;5;241m.\u001b[39mappend(\u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     19\u001b[0m     output[split] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(losses) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(losses)\n\u001b[0;32m     21\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "max_iters = 20\n",
    "eval_interval = 5\n",
    "learning_rate = 1e-4\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "for iteration in range(max_iters):\n",
    "    for batch_idx, (x_batch, y_batch) in enumerate(train_loader):\n",
    "        # Evaluation\n",
    "        if batch_idx % eval_interval == 0 or batch_idx == len(train_loader) - 1:\n",
    "            losses = estimate_loss(\n",
    "                model=model,\n",
    "                train_loader=train_loader,\n",
    "                val_loader=val_loader,\n",
    "            )\n",
    "            train_losses.append(losses['train'])\n",
    "            val_losses.append(losses['val'])\n",
    "\n",
    "            print(\n",
    "                f\"iteration {iteration} / step {batch_idx}: \"\n",
    "                f\"train loss {losses['train']:.4f}, \"\n",
    "                f\"val loss {losses['val']:.4f}\"\n",
    "            )\n",
    "\n",
    "        # Training step\n",
    "        logits, loss = model(x_batch, y_batch)\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Save checkpoint\n",
    "    save_checkpoint(\n",
    "        model=model,\n",
    "        optimizer=optimizer,\n",
    "        epoch=iteration,\n",
    "        loss=loss.item(),\n",
    "        file_path=f\"../output/fine_tuning/run_1/checkpoint_{iteration}.pth\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(train_losses, label=\"Train Loss\")\n",
    "plt.plot(val_losses, label=\"Validation Loss\")\n",
    "plt.xlabel(\"Evaluation Step\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training and Validation Loss Over Time\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You: Hola\n",
      "Assistant: Si no tardo Lomeli<|separator|>Thhhh: 8116?\n"
     ]
    }
   ],
   "source": [
    "def get_input_tokens(message: str) -> torch.Tensor:\n",
    "    input_tokens = tokenizer.encode(\n",
    "        f\"<|startoftext|>{message}<|separator|>\", allowed_special=\"all\")\n",
    "    input_tokens = torch.tensor(\n",
    "        input_tokens, dtype=torch.long).unsqueeze(0).to(device)\n",
    "    return input_tokens\n",
    "\n",
    "\n",
    "user_message = \"Hola\"\n",
    "input_tokens = get_input_tokens(message=user_message)\n",
    "model_answer = \"\"\n",
    "\n",
    "model.eval()\n",
    "while True:\n",
    "    output_tokens = model.generate(input_tokens=input_tokens, max_new_tokens=1)\n",
    "    last_generated_token = output_tokens[0, -1].item()\n",
    "    if last_generated_token == tokenizer.special_tokens[\"<|endoftext|>\"]:\n",
    "        break\n",
    "\n",
    "    input_tokens = torch.cat((input_tokens, output_tokens[:, -1:]), dim=1)\n",
    "    model_answer += tokenizer.decode([last_generated_token])\n",
    "\n",
    "    if len(output_tokens[0]) > block_size:\n",
    "        break\n",
    "\n",
    "print(f\"You: {user_message}\")\n",
    "print(f\"Assistant: {model_answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vincent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
