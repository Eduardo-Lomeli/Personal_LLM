{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load the fine-tuning data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3494"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "file_path = \"../output/fine_tuning/data/fine_tuning_ready.json\"\n",
    "with open(file_path, \"r\") as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Load the tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from minbpe import RegexTokenizer\n",
    "\n",
    "tokenizer = RegexTokenizer()\n",
    "tokenizer.load(model_file=\"../output/tokenizer/my_dataset_tokenizer.model\")\n",
    "\n",
    "\n",
    "def get_vocab_size(tokenizer: RegexTokenizer) -> int:\n",
    "    vocab = tokenizer.vocab\n",
    "    special_tokens = tokenizer.special_tokens\n",
    "\n",
    "    return len(vocab) + len(special_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. System message"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The system message will be added to the beginning of each conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"Te llamo Clon de Eduardo para que ayudes a la gente a responder a sus preguntas. Intenta ser amable con ellos, resp√≥ndeles con gentileza, o si alguien te molesta, intenta calmarte y no enfadarte con √©l\"\n",
    "system_entry = {\n",
    "    \"role\": \"system\",\n",
    "    \"content\": system_message\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Check if block size is not exceeded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "708"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_tokens = 0\n",
    "block_size = 1024\n",
    "for conversation in data:\n",
    "    concatenated_messages = \"\"\n",
    "    for message in conversation:\n",
    "        content = message[\"content\"]\n",
    "        concatenated_messages += content + \"\\n\"\n",
    "\n",
    "    tokens = tokenizer.encode(concatenated_messages)\n",
    "    max_tokens = max(max_tokens, len(tokens))\n",
    "    if len(tokens) > block_size:\n",
    "        print(\n",
    "            f\"Error: Token length exceeds block size. Length: {len(tokens)}, Block size: {block_size}\")\n",
    "\n",
    "max_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Add special tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![masked_version](../images/masking.svg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = {\n",
    "    \"start\": \"<|start_turn|>\",\n",
    "    \"end\": \"<|end_turn|>\",\n",
    "    \"separator\": \"<|separator|>\",\n",
    "    \"eos\": \"<|endoftext|>\"\n",
    "}\n",
    "\n",
    "\n",
    "def format_message(message: dict) -> str:\n",
    "    return f\"{tokens['start']}{message['role']}{tokens['separator']}{message['content']}{tokens['end']}\"\n",
    "\n",
    "\n",
    "fine_tuning_data = []\n",
    "for conversation in data:\n",
    "    concatenated_messages = \"\"\n",
    "\n",
    "    for message in conversation:\n",
    "        role = message[\"role\"]\n",
    "        if role == \"user\":\n",
    "            if len(concatenated_messages) == 0:\n",
    "                concatenated_messages += format_message({\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": system_message\n",
    "                })\n",
    "            concatenated_messages += format_message(message)\n",
    "        elif role == \"assistant\":\n",
    "            concatenated_messages += format_message(message)\n",
    "            encoded_message = tokenizer.encode(\n",
    "                text=concatenated_messages + tokens[\"eos\"],\n",
    "                allowed_special=\"all\"\n",
    "            )\n",
    "            fine_tuning_data.append(encoded_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13957"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fine_tuning_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|start_turn|>assistant<|separator|>Yeyis\\nVas a venir?<|end_turn|><|endoftext|>'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(fine_tuning_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|start_turn|>assistant<|separator|>Yeyis\\nVas a venir?<|end_turn|><|start_turn|>user<|separator|>Siii\\nSabes que es NAT?<|end_turn|><|start_turn|>assistant<|separator|>Creo que un tipo de red\\nO algo de almacenamiento\\nYa lleg√≥ sushi<|end_turn|><|endoftext|>'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(fine_tuning_data[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's add a padding token to make sure that the sequences have the same shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "956"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_sequence_length = max(\n",
    "    len(sequence) for sequence in fine_tuning_data)\n",
    "max_sequence_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([13957, 956])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.manual_seed(3647)\n",
    "\n",
    "# The model will ignore the padding tokens during training.\n",
    "# In other words, the loss will not be calculated for these tokens.\n",
    "padding_token = tokenizer.special_tokens[\"<|padding|>\"]\n",
    "\n",
    "\n",
    "def apply_padding_to_data(data: list[list[int]], max_sequence_length: int, padding_token: int) -> torch.Tensor:\n",
    "    tensors = []\n",
    "    for i in range(len(data)):\n",
    "        tensor = torch.tensor(data[i])\n",
    "        padded_tensor = torch.nn.functional.pad(\n",
    "            input=tensor,\n",
    "            # for right padding:\n",
    "            pad=(0, max_sequence_length - len(tensor)),\n",
    "            # pad=(max_sequence_length - len(tensor), 0),\n",
    "            value=padding_token\n",
    "        )\n",
    "        tensors.append(padded_tensor)\n",
    "\n",
    "    return torch.stack(tensors)\n",
    "\n",
    "\n",
    "train_data_tensor = apply_padding_to_data(\n",
    "    data=fine_tuning_data,\n",
    "    max_sequence_length=max_sequence_length,\n",
    "    padding_token=padding_token\n",
    ")\n",
    "train_data_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([13259, 956]), torch.Size([698, 956]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_index = int(0.95*len(train_data_tensor))\n",
    "train_data_split = train_data_tensor[:split_index]\n",
    "val_data_split = train_data_tensor[split_index:]\n",
    "\n",
    "train_data_split.shape, val_data_split.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Creat the data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "class FineTuningDataset(Dataset):\n",
    "    def __init__(self, data: torch.Tensor, device: torch.device, padding_token: int):\n",
    "        self.data = data  # shape: (num_samples, block_size)\n",
    "        self.device = device\n",
    "        self.padding_token = padding_token\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index: int) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        sample = self.data[index]\n",
    "        x = sample.to(self.device)\n",
    "        y = sample[1:].to(self.device)\n",
    "        padding_tensor = torch.tensor([self.padding_token], device=self.device)\n",
    "        y = torch.cat((y, padding_tensor))\n",
    "        masked_y = self.apply_mask_to_target(y)\n",
    "        return x, masked_y\n",
    "\n",
    "    def apply_mask_to_target(self, y: torch.Tensor) -> torch.Tensor:\n",
    "        assistant_turn_tokens = torch.tensor(\n",
    "            tokenizer.encode(\n",
    "                \"<|start_turn|>assistant<|separator|>\",\n",
    "                allowed_special=\"all\"\n",
    "            ),\n",
    "            device=self.device\n",
    "        )\n",
    "        sublist_length = len(assistant_turn_tokens)\n",
    "\n",
    "        # Find the last occurrence of assistant_turn_tokens in y\n",
    "        # This only works if yoou use right padding\n",
    "        last_occurrence = -1\n",
    "        for i in range(len(y) - sublist_length + 1):\n",
    "            if torch.all(y[i:i+sublist_length] == assistant_turn_tokens):\n",
    "                last_occurrence = i + sublist_length - 1\n",
    "\n",
    "        if last_occurrence != -1:\n",
    "            y[:last_occurrence + 1] = self.padding_token\n",
    "\n",
    "        return y\n",
    "\n",
    "\n",
    "batch_size = 8\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "train_dataset = FineTuningDataset(\n",
    "    data=train_data_split,\n",
    "    device=device,\n",
    "    padding_token=padding_token\n",
    ")\n",
    "train_loader = DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_dataset = FineTuningDataset(\n",
    "    data=val_data_split,\n",
    "    device=device,\n",
    "    padding_token=padding_token\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    dataset=val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([8, 956]), torch.Size([8, 956]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = next(iter(train_loader))\n",
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([8, 956]), torch.Size([8, 956]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = next(iter(val_loader))\n",
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load the saved checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36.23425 M parameters\n"
     ]
    }
   ],
   "source": [
    "from transformer.model import GPTLanguageModel\n",
    "\n",
    "block_size = 1024\n",
    "n_embd = 512\n",
    "n_head = 32\n",
    "n_layer = 6\n",
    "dropout = 0.2\n",
    "vocab_size = get_vocab_size(tokenizer)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "model = GPTLanguageModel(\n",
    "    vocab_size=vocab_size,\n",
    "    block_size=block_size,\n",
    "    n_embd=n_embd,\n",
    "    n_head=n_head,\n",
    "    n_layer=n_layer,\n",
    "    dropout=dropout,\n",
    "    device=device,\n",
    "    ignore_index=tokenizer.special_tokens[\"<|padding|>\"],\n",
    ").to(device)\n",
    "\n",
    "print(sum(p.numel() for p in model.parameters())/1e6, 'M parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint_path = \"../output/pre_training/run_4/checkpoint_15000.pth\"\n",
    "checkpoint = torch.load(checkpoint_path, weights_only=True)\n",
    "model_state_dict = checkpoint[\"model_state_dict\"]\n",
    "model.load_state_dict(model_state_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate from the model to make sure that the weights were loaded correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hola como estas?  Cr√©dito poner23 m desde31 m desde31ti.a√± imagen,fica!a√± Cuando yiry artefactos habit apa random Ten, so Pan26 dormir√°s?49 serun salchichas bols?49 ser b Bluetooth gust√≥hoome21 amigui31 m.ja ü§®ü§®ÔøΩun prior verdad23er canlig, para Servicio RH Zale02dala ocaleraona02dala ocaleraona Keiarita, obli so Pan faltabanMS fin ulti agu√≠a02dala ocaleraona Keiar burbu07 sugi15omeit apa random\n"
     ]
    }
   ],
   "source": [
    "input_tokens = tokenizer.encode(\"Hola como estas? \", allowed_special=\"all\")\n",
    "input_tokens = torch.tensor(\n",
    "    input_tokens, dtype=torch.long).unsqueeze(0).to(device)\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    output = model.generate(input_tokens=input_tokens, max_new_tokens=100)\n",
    "\n",
    "print(tokenizer.decode(output[0].tolist()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Estimate loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def estimate_loss(\n",
    "    model: torch.nn.Module,\n",
    "    train_loader: DataLoader,\n",
    "    val_loader: DataLoader,\n",
    ") -> Dict[str, float]:\n",
    "    output = {}\n",
    "    model.eval()\n",
    "\n",
    "    for split, loader in [('train', train_loader), ('val', val_loader)]:\n",
    "        losses = torch.zeros(len(loader))\n",
    "        for i, (x, y) in enumerate(loader):\n",
    "            with torch.no_grad():\n",
    "                _, loss = model(x, y)\n",
    "            losses[i] = loss.item()\n",
    "        output[split] = losses.mean().item()\n",
    "\n",
    "    model.train()\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Save checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(\n",
    "    model: GPTLanguageModel,\n",
    "    optimizer: torch.optim.Optimizer,\n",
    "    epoch: int,\n",
    "    loss: float,\n",
    "    file_path: str = \"checkpoint.pth\"\n",
    ") -> None:\n",
    "    checkpoint = {\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'loss': loss\n",
    "    }\n",
    "    torch.save(checkpoint, file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training on batches:   0%|          | 0/1658 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 / step 0: train loss 14.1355, val loss 13.9725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training on batches:   0%|          | 5/1658 [36:28<95:02:11, 206.98s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 / step 5: train loss 9.1323, val loss 9.3545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training on batches:   1%|          | 10/1658 [5:43:54<646:16:32, 1411.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 / step 10: train loss 8.2541, val loss 8.5205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training on batches:   1%|          | 15/1658 [10:12:31<644:18:16, 1411.74s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 / step 15: train loss 7.5693, val loss 7.7722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training on batches:   1%|          | 20/1658 [15:07:16<693:08:40, 1523.39s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 / step 20: train loss 6.9133, val loss 7.1547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training on batches:   2%|‚ñè         | 25/1658 [19:29:36<1273:18:23, 2807.04s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 19\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_idx, (x_batch, y_batch) \u001b[38;5;129;01min\u001b[39;00m tqdm(\n\u001b[0;32m     13\u001b[0m     iterable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28menumerate\u001b[39m(train_loader),\n\u001b[0;32m     14\u001b[0m     desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining on batches\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     15\u001b[0m     total\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(train_loader)\n\u001b[0;32m     16\u001b[0m ):\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;66;03m# Evaluation\u001b[39;00m\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m batch_idx \u001b[38;5;241m%\u001b[39m eval_interval \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m batch_idx \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(train_loader) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m---> 19\u001b[0m         losses \u001b[38;5;241m=\u001b[39m \u001b[43mestimate_loss\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[43m            \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_loader\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     24\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m     25\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00miteration\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m / step \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbatch_idx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     26\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain loss \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlosses[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     27\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval loss \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlosses[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     28\u001b[0m         )\n\u001b[0;32m     29\u001b[0m         train_losses\u001b[38;5;241m.\u001b[39mappend(losses[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\Eduar\\miniconda3\\envs\\vincent\\lib\\site-packages\\torch\\utils\\_contextlib.py:120\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    119\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 120\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "Cell \u001b[1;32mIn[19], line 18\u001b[0m, in \u001b[0;36mestimate_loss\u001b[1;34m(model, train_loader, val_loader)\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m     17\u001b[0m             _, loss \u001b[38;5;241m=\u001b[39m model(x, y)\n\u001b[1;32m---> 18\u001b[0m         losses[i] \u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m     output[split] \u001b[38;5;241m=\u001b[39m losses\u001b[38;5;241m.\u001b[39mmean()\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m     21\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "max_iters = 50\n",
    "eval_interval = 5\n",
    "learning_rate = 1e-4\n",
    "save_interval = 20\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "train_losses, val_losses = [], []\n",
    "\n",
    "for iteration in range(max_iters):\n",
    "    for batch_idx, (x_batch, y_batch) in tqdm(\n",
    "        iterable=enumerate(train_loader),\n",
    "        desc=\"Training on batches\",\n",
    "        total=len(train_loader)\n",
    "    ):\n",
    "        # Evaluation\n",
    "        if batch_idx % eval_interval == 0 or batch_idx == len(train_loader) - 1:\n",
    "            losses = estimate_loss(\n",
    "                model=model,\n",
    "                train_loader=train_loader,\n",
    "                val_loader=val_loader\n",
    "            )\n",
    "            print(\n",
    "                f\"Epoch {iteration} / step {batch_idx}: \"\n",
    "                f\"train loss {losses['train']:.4f}, \"\n",
    "                f\"val loss {losses['val']:.4f}\"\n",
    "            )\n",
    "            train_losses.append(losses['train'])\n",
    "            val_losses.append(losses['val'])\n",
    "\n",
    "        # Training step\n",
    "        logits, loss = model(x_batch, y_batch)\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Save checkpoint\n",
    "    if iteration % save_interval == 0 or iteration == max_iters - 1:\n",
    "        save_checkpoint(\n",
    "            model=model,\n",
    "            optimizer=optimizer,\n",
    "            epoch=iteration,\n",
    "            loss=loss.item(),\n",
    "            file_path=f\"../output/fine_tuning/qa/base/run_1/checkpoint_{iteration}.pth\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(train_losses, label=\"Train Loss\")\n",
    "plt.plot(val_losses, label=\"Validation Loss\")\n",
    "plt.xlabel(\"Evaluation Step\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training and Validation Loss Over Time\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../output/fine_tuning/qa/base/run_3/checkpoint_49.pth'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m checkpoint_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../output/fine_tuning/qa/base/run_3/checkpoint_49.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 2\u001b[0m checkpoint \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheckpoint_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m model_state_dict \u001b[38;5;241m=\u001b[39m checkpoint[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_state_dict\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m      4\u001b[0m model\u001b[38;5;241m.\u001b[39mload_state_dict(model_state_dict)\n",
      "File \u001b[1;32mc:\\Users\\Eduar\\miniconda3\\envs\\vincent\\lib\\site-packages\\torch\\serialization.py:1484\u001b[0m, in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[0;32m   1481\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m   1482\u001b[0m     pickle_load_args[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1484\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[0;32m   1485\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[0;32m   1486\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[0;32m   1487\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[0;32m   1488\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[0;32m   1489\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n",
      "File \u001b[1;32mc:\\Users\\Eduar\\miniconda3\\envs\\vincent\\lib\\site-packages\\torch\\serialization.py:759\u001b[0m, in \u001b[0;36m_open_file_like\u001b[1;34m(name_or_buffer, mode)\u001b[0m\n\u001b[0;32m    757\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer: FileLike, mode: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m _opener[IO[\u001b[38;5;28mbytes\u001b[39m]]:\n\u001b[0;32m    758\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[1;32m--> 759\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    760\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    761\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "File \u001b[1;32mc:\\Users\\Eduar\\miniconda3\\envs\\vincent\\lib\\site-packages\\torch\\serialization.py:740\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[1;34m(self, name, mode)\u001b[0m\n\u001b[0;32m    739\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name: Union[\u001b[38;5;28mstr\u001b[39m, os\u001b[38;5;241m.\u001b[39mPathLike[\u001b[38;5;28mstr\u001b[39m]], mode: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 740\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../output/fine_tuning/qa/base/run_3/checkpoint_49.pth'"
     ]
    }
   ],
   "source": [
    "checkpoint_path = \"../output/fine_tuning/qa/base/run_3/checkpoint_49.pth\"\n",
    "checkpoint = torch.load(checkpoint_path, weights_only=True)\n",
    "model_state_dict = checkpoint[\"model_state_dict\"]\n",
    "model.load_state_dict(model_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 54\u001b[0m\n\u001b[0;32m     43\u001b[0m turns \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     44\u001b[0m     {\n\u001b[0;32m     45\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msystem\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     51\u001b[0m     },\n\u001b[0;32m     52\u001b[0m ]\n\u001b[0;32m     53\u001b[0m input_tokens \u001b[38;5;241m=\u001b[39m get_input_tokens(turns\u001b[38;5;241m=\u001b[39mturns)\n\u001b[1;32m---> 54\u001b[0m model_answer \u001b[38;5;241m=\u001b[39m \u001b[43mget_generated_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_tokens\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m turns\u001b[38;5;241m.\u001b[39mappend({\n\u001b[0;32m     56\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124massistant\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     57\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: model_answer\n\u001b[0;32m     58\u001b[0m })\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m turn \u001b[38;5;129;01min\u001b[39;00m turns:\n",
      "Cell \u001b[1;32mIn[25], line 21\u001b[0m, in \u001b[0;36mget_generated_message\u001b[1;34m(input_tokens)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 21\u001b[0m         output_tokens \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madvanced_generation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[43m            \u001b[49m\u001b[43minput_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_tokens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m.9\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_k\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m         last_generated_token \u001b[38;5;241m=\u001b[39m output_tokens[\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m     24\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m last_generated_token \u001b[38;5;241m==\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mspecial_tokens[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<|endoftext|>\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[1;32mh:\\Mi unidad\\6to Semestre Ceti\\Inteligencia artificial\\LLM\\Personal_LLM\\Personal_LLM\\notebooks\\..\\transformer\\model.py:194\u001b[0m, in \u001b[0;36mGPTLanguageModel.advanced_generation\u001b[1;34m(self, input_tokens, max_new_tokens, temperature, top_k, top_p)\u001b[0m\n\u001b[0;32m    192\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(max_new_tokens):\n\u001b[0;32m    193\u001b[0m     cropped_input \u001b[38;5;241m=\u001b[39m input_tokens[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblock_size:]\n\u001b[1;32m--> 194\u001b[0m     logits, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcropped_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    195\u001b[0m     logits \u001b[38;5;241m=\u001b[39m logits[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, :] \u001b[38;5;241m/\u001b[39m temperature\n\u001b[0;32m    197\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m top_k \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Eduar\\miniconda3\\envs\\vincent\\lib\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1774\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1775\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Eduar\\miniconda3\\envs\\vincent\\lib\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1781\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1782\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1783\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1784\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1785\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1786\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1788\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1789\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mh:\\Mi unidad\\6to Semestre Ceti\\Inteligencia artificial\\LLM\\Personal_LLM\\Personal_LLM\\notebooks\\..\\transformer\\model.py:136\u001b[0m, in \u001b[0;36mGPTLanguageModel.forward\u001b[1;34m(self, input_tokens, targets)\u001b[0m\n\u001b[0;32m    133\u001b[0m positional_embedding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mposition_embedding_table(\n\u001b[0;32m    134\u001b[0m     torch\u001b[38;5;241m.\u001b[39marange(T, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice))\n\u001b[0;32m    135\u001b[0m x \u001b[38;5;241m=\u001b[39m token_embedding \u001b[38;5;241m+\u001b[39m positional_embedding\n\u001b[1;32m--> 136\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mblocks\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    137\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfinal_layer_norm(x)\n\u001b[0;32m    138\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfinal_linear_layer(x)\n",
      "File \u001b[1;32mc:\\Users\\Eduar\\miniconda3\\envs\\vincent\\lib\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1774\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1775\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Eduar\\miniconda3\\envs\\vincent\\lib\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1781\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1782\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1783\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1784\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1785\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1786\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1788\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1789\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\Eduar\\miniconda3\\envs\\vincent\\lib\\site-packages\\torch\\nn\\modules\\container.py:250\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    246\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    247\u001b[0m \u001b[38;5;124;03mRuns the forward pass.\u001b[39;00m\n\u001b[0;32m    248\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 250\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    251\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Eduar\\miniconda3\\envs\\vincent\\lib\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1774\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1775\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Eduar\\miniconda3\\envs\\vincent\\lib\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1781\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1782\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1783\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1784\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1785\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1786\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1788\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1789\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mh:\\Mi unidad\\6to Semestre Ceti\\Inteligencia artificial\\LLM\\Personal_LLM\\Personal_LLM\\notebooks\\..\\transformer\\model.py:87\u001b[0m, in \u001b[0;36mBlock.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m---> 87\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself_attention\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer_norm_1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     88\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeed_forward(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer_norm_2(x))\n\u001b[0;32m     89\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[1;32mc:\\Users\\Eduar\\miniconda3\\envs\\vincent\\lib\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1774\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1775\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Eduar\\miniconda3\\envs\\vincent\\lib\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1781\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1782\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1783\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1784\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1785\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1786\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1788\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1789\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mh:\\Mi unidad\\6to Semestre Ceti\\Inteligencia artificial\\LLM\\Personal_LLM\\Personal_LLM\\notebooks\\..\\transformer\\model.py:46\u001b[0m, in \u001b[0;36mMultiHeadAttention.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m---> 46\u001b[0m     out \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([h(x) \u001b[38;5;28;01mfor\u001b[39;00m h \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mheads], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     47\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprojection(out))\n\u001b[0;32m     48\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[1;32mh:\\Mi unidad\\6to Semestre Ceti\\Inteligencia artificial\\LLM\\Personal_LLM\\Personal_LLM\\notebooks\\..\\transformer\\model.py:46\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m---> 46\u001b[0m     out \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([\u001b[43mh\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m h \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mheads], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     47\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprojection(out))\n\u001b[0;32m     48\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[1;32mc:\\Users\\Eduar\\miniconda3\\envs\\vincent\\lib\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1774\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1775\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Eduar\\miniconda3\\envs\\vincent\\lib\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1781\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1782\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1783\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1784\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1785\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1786\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1788\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1789\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mh:\\Mi unidad\\6to Semestre Ceti\\Inteligencia artificial\\LLM\\Personal_LLM\\Personal_LLM\\notebooks\\..\\transformer\\model.py:26\u001b[0m, in \u001b[0;36mHead.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     24\u001b[0m weights \u001b[38;5;241m=\u001b[39m q \u001b[38;5;241m@\u001b[39m k\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m*\u001b[39m k\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m0.5\u001b[39m\n\u001b[0;32m     25\u001b[0m weights \u001b[38;5;241m=\u001b[39m weights\u001b[38;5;241m.\u001b[39mmasked_fill(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtril[:T, :T] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-inf\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m---> 26\u001b[0m weights \u001b[38;5;241m=\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msoftmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     27\u001b[0m weights \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(weights)\n\u001b[0;32m     28\u001b[0m v \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalue(x)\n",
      "File \u001b[1;32mc:\\Users\\Eduar\\miniconda3\\envs\\vincent\\lib\\site-packages\\torch\\nn\\functional.py:2133\u001b[0m, in \u001b[0;36msoftmax\u001b[1;34m(input, dim, _stacklevel, dtype)\u001b[0m\n\u001b[0;32m   2131\u001b[0m     dim \u001b[38;5;241m=\u001b[39m _get_softmax_dim(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msoftmax\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdim(), _stacklevel)\n\u001b[0;32m   2132\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 2133\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msoftmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdim\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2134\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2135\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msoftmax(dim, dtype\u001b[38;5;241m=\u001b[39mdtype)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def get_input_tokens(turns: list[dict]) -> list[int]:\n",
    "    formatted_input = \"\"\n",
    "    for turn in turns:\n",
    "        role = turn[\"role\"]\n",
    "        content = turn[\"content\"]\n",
    "        formatted_input += f\"{tokens['start']}{role}{tokens['separator']}{content}{tokens['end']}\"\n",
    "\n",
    "    formatted_input += f\"{tokens['start']}assistant{tokens['separator']}\"\n",
    "\n",
    "    input_tokens = tokenizer.encode(formatted_input, allowed_special=\"all\")\n",
    "    input_tokens = torch.tensor(input_tokens, dtype=torch.long)\n",
    "    input_tokens = input_tokens.unsqueeze(0).to(device)\n",
    "    return input_tokens\n",
    "\n",
    "\n",
    "def get_generated_message(input_tokens: list[int]) -> str:\n",
    "    model_answer = \"\"\n",
    "    model.eval()\n",
    "    while True:\n",
    "        try:\n",
    "            output_tokens = model.advanced_generation(\n",
    "                input_tokens=input_tokens, max_new_tokens=1, temperature=.9, top_k=50, top_p=None)\n",
    "            last_generated_token = output_tokens[0, -1].item()\n",
    "            if last_generated_token == tokenizer.special_tokens[\"<|endoftext|>\"]:\n",
    "                break\n",
    "\n",
    "            if last_generated_token == tokenizer.special_tokens[\"<|end_turn|>\"]:\n",
    "                break\n",
    "\n",
    "            input_tokens = torch.cat(\n",
    "                (input_tokens, output_tokens[:, -1:]), dim=1)\n",
    "            model_answer += tokenizer.decode([last_generated_token])\n",
    "\n",
    "            if len(output_tokens[0]) > block_size:\n",
    "                break\n",
    "        except Exception:\n",
    "            continue\n",
    "\n",
    "    return model_answer\n",
    "\n",
    "\n",
    "user_message = \"Hola, ¬øc√≥mo est√°s?\"\n",
    "turns = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": system_message\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": user_message\n",
    "    },\n",
    "]\n",
    "input_tokens = get_input_tokens(turns=turns)\n",
    "model_answer = get_generated_message(input_tokens=input_tokens)\n",
    "turns.append({\n",
    "    \"role\": \"assistant\",\n",
    "    \"content\": model_answer\n",
    "})\n",
    "\n",
    "for turn in turns:\n",
    "    role = turn[\"role\"]\n",
    "    if role == \"user\":\n",
    "        print(f\"You: {turn['content']}\")\n",
    "    elif role == \"assistant\":\n",
    "        print(f\"Assistant: {turn['content']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turns = turns[:-2]  # Uncomment this if you want to retry the generation\n",
    "user_message = \"ÿ¥ÿ≠ÿßŸÑ ŸÖŸÜ ÿØŸÇŸäŸÇÿ© ŸÉÿßŸäŸÜÿ© ŸÅÿßŸÑŸÜŸáÿßÿ±ÿü\"\n",
    "turns.append({\n",
    "    \"role\": \"user\",\n",
    "    \"content\": user_message\n",
    "})\n",
    "input_tokens = get_input_tokens(turns=turns)\n",
    "model_answer = get_generated_message(input_tokens=input_tokens)\n",
    "turns.append({\n",
    "    \"role\": \"assistant\",\n",
    "    \"content\": model_answer\n",
    "})\n",
    "for turn in turns:\n",
    "    role = turn[\"role\"]\n",
    "    if role == \"user\":\n",
    "        print(f\"You: {turn['content']}\")\n",
    "    elif role == \"assistant\":\n",
    "        print(f\"Assistant: {turn['content']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You: ÿ¥ŸÜŸà ÿ≥ŸÖŸäÿ™ŸÉÿü\n",
      "Assistant: ÿ®ŸàÿØŸÖÿßÿ∫ÿå ŸÉÿßŸäŸÜ ÿ¥Ÿä ÿ≠ÿßÿ¨ÿ© ŸÜÿπÿßŸàŸÜŸÉ ÿ®Ÿáÿßÿü\n",
      "You: ÿ¥ÿ≠ÿßŸÑ ŸÖŸÜ ÿØŸÇŸäŸÇÿ© ŸÉÿßŸäŸÜÿ© ŸÅÿßŸÑŸÜŸáÿßÿ±ÿü\n",
      "Assistant: ŸÅÿßŸÑÿπÿßŸÑŸÖ ŸÉÿßŸäŸÜ ÿ™ŸÇÿ±Ÿäÿ®ÿß 1440 ÿØŸÇŸäŸÇÿ© ŸÅÿßŸÑŸÜŸáÿßÿ±.\n",
      "You: ÿßŸÑŸÑÿπÿ≤ ÿßŸÑŸÑŸá Ÿäÿ≠ŸÅÿ∂ŸÉ.\n",
      "Assistant: ÿßŸÑŸâ ÿπŸÜÿØŸÉ ÿ¥Ÿä ÿ≥ÿ§ÿßŸÑ ÿÆŸàÿ± ÿ∫ŸàŸÑŸáÿßŸÑŸä.\n"
     ]
    }
   ],
   "source": [
    "# turns = turns[:-2] # Uncomment this if you want to retry the generation\n",
    "user_message = \"ÿßŸÑŸÑÿπÿ≤ ÿßŸÑŸÑŸá Ÿäÿ≠ŸÅÿ∂ŸÉ.\"\n",
    "turns.append({\n",
    "    \"role\": \"user\",\n",
    "    \"content\": user_message\n",
    "})\n",
    "input_tokens = get_input_tokens(turns=turns)\n",
    "model_answer = get_generated_message(input_tokens=input_tokens)\n",
    "turns.append({\n",
    "    \"role\": \"assistant\",\n",
    "    \"content\": model_answer\n",
    "})\n",
    "for turn in turns:\n",
    "    role = turn[\"role\"]\n",
    "    if role == \"user\":\n",
    "        print(f\"You: {turn['content']}\")\n",
    "    elif role == \"assistant\":\n",
    "        print(f\"Assistant: {turn['content']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vincent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
